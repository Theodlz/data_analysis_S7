{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e408cfdd-7eb9-4711-b06c-582bee7ab319",
   "metadata": {},
   "source": [
    "# LSTM PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf4e3f1-3e7c-49c4-86b2-7f36b08808f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6719b0c2-3465-4c7a-a216-5cacf9031f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.getcwd()+\"/pre_processing/dataset_traite.csv\", sep=',', parse_dates=[\"DateTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d00183-f66e-489b-aa07-1485bf145ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm = df.set_index('DateTime')\n",
    "df_lstm = df_lstm.resample('h').mean()\n",
    "df_lstm['Date'] = pd.to_datetime(df_lstm.index.date)\n",
    "temperatures = pd.read_csv(\"pre_processing/temperatures.csv\", parse_dates=['Date'], index_col='Date')\n",
    "temperatures['avg_t'] = (temperatures['max_t'] - temperatures['min_t'])/2\n",
    "df_lstm = df_lstm.join(temperatures, how=\"left\", on='Date')\n",
    "df_lstm = df_lstm.drop(columns=['Date','max_t','min_t'])\n",
    "#df_lstm[\"Day\"] = df_lstm.index.dayofweek+1\n",
    "#y = pd.get_dummies(df_lstm.Day, prefix='Day')\n",
    "#df_lstm = df_lstm.join(y, how=\"left\")\n",
    "#df_lstm = df_lstm.drop(columns=[\"Day\"])\n",
    "df_lstm = df_lstm.drop(columns=[\"Global_reactive_power\"])\n",
    "df_lstm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24154a-caa6-4313-bd9c-9c1b55888fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "df_lstm[df_lstm.columns] = scaler.fit_transform(df_lstm[df_lstm.columns])\n",
    "df_lstm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075e5447-77c1-4755-bc6b-10673a5364b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c5549-38ff-43ab-8a0f-4986189e0c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_to_supervised(df, steps_ahead = 1, col_to_predict=\"Global_active_power\"):\n",
    "#     data = pd.DataFrame(df)\n",
    "#     n_vars = data.shape[1]\n",
    "#     columns = []\n",
    "#     columns.append(data.shift(0))\n",
    "#     # temp = data.shift(0)\n",
    "#     columns.append(data.shift(-steps_ahead)[col_to_predict])\n",
    "#     df_labeled = pd.concat(columns, axis=1)\n",
    "#     names = [col + \"(t-1)\" for col in df.columns]\n",
    "#     names.append(f\"{col_to_predict}(t)\")\n",
    "#     print(names)\n",
    "#     df_labeled.columns = names\n",
    "#     df_labeled.dropna(inplace=True)\n",
    "    \n",
    "#     return df_labeled\n",
    "\n",
    "def data_to_supervised(df, col_to_predict=\"Global_active_power\"):\n",
    "    data = pd.DataFrame(df)\n",
    "    n_vars = data.shape[1]\n",
    "    columns = []\n",
    "    columns.append(data.shift(1))\n",
    "    # temp = data.shift(0)\n",
    "    columns.append(data.shift(0)[col_to_predict])\n",
    "    df_labeled = pd.concat(columns, axis=1)\n",
    "    names = [col + \"(t-1)\" for col in df.columns]\n",
    "    names.append(f\"{col_to_predict}(t)\")\n",
    "    print(names)\n",
    "    df_labeled.columns = names\n",
    "    df_labeled.dropna(inplace=True)\n",
    "    \n",
    "    return df_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfcc11-be8c-4577-94cd-a890851140de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm = data_to_supervised(df_lstm)\n",
    "df_lstm.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daac140-3b6e-4353-aecc-f72bdff0b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df_lstm.values\n",
    "\n",
    "trainsize = 0.8\n",
    "n_rows = round(len(values)*trainsize)\n",
    "print(f\"Taille du trainset : {n_rows}\")\n",
    "\n",
    "train = values[:n_rows, :]\n",
    "test = values[n_rows:, :]\n",
    "\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D format as expected by LSTMs [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c985b-947f-407c-b02c-5a5f46b59230",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#recurrent_activation ='selu' # 1er place\n",
    "#recurrent_activation ='softsign' # 2e place\n",
    "\n",
    "model.add(LSTM(125, input_shape=(train_X.shape[1], train_X.shape[2]),recurrent_activation ='sigmoid',activation='tanh',return_sequences=False))\n",
    "#model.add(LSTM(2*24,recurrent_activation ='sigmoid',activation='tanh',return_sequences=True))\n",
    "#model.add(LSTM(2*24,recurrent_activation ='sigmoid',activation='tanh'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "#model.compile(optimizer=tensorflow.keras.optimizers.SGD(learning_rate=0.001),\n",
    "             # loss=tensorflow.keras.losses.MeanSquaredError(),\n",
    "             # metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1129397-3f6a-4c9f-b8be-4c697c014eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=75, batch_size=70, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a373b7-35c8-44f9-aead-bb543d0f0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "size = df_lstm.shape[1]-1\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], size))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1-size:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1-size:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8857fd-3b2f-4fbe-9525-c123fef4321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bc2c4f-f4e8-4ce3-94b9-59730daf0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c39a5-7440-4e50-b8ed-7691bb600b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "r2 = sklearn.metrics.r2_score(inv_y, inv_yhat)\n",
    "print(r2)\n",
    "r_adjusted = 1 - ( 1-r2 ) * ( len(test_y) - 1 ) / ( len(test_y) - test_X.shape[1] - 1 )\n",
    "print(r_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d730f6-ab79-4028-b23e-e4576c0c03bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=[x for x in range(100)]\n",
    "plt.figure(figsize=(40,10))\n",
    "plt.plot(aa, inv_y[:100], marker='.', label=\"actual\")\n",
    "plt.plot(aa, inv_yhat[:100], 'r', label=\"prediction\")\n",
    "plt.ylabel(df.columns[1], size=15)\n",
    "plt.xlabel('Time step for first 500 hours', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff1106f-f911-4bcc-82fa-a4ea695f1e13",
   "metadata": {},
   "source": [
    "# LSTM by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3894dc-b760-49a8-8e76-74265d0d7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm = df.set_index('DateTime')\n",
    "df_lstm = df_lstm.resample('h').mean()\n",
    "df_lstm['Date'] = pd.to_datetime(df_lstm.index.date)\n",
    "temperatures = pd.read_csv(\"pre_processing/temperatures.csv\", parse_dates=['Date'], index_col='Date')\n",
    "temperatures['avg_t'] = (temperatures['max_t'] - temperatures['min_t'])/2\n",
    "df_lstm = df_lstm.join(temperatures, how=\"left\", on='Date')\n",
    "df_lstm = df_lstm.drop(columns=['Date','max_t','min_t'])\n",
    "#df_lstm[\"Day\"] = df_lstm.index.dayofweek+1\n",
    "#y = pd.get_dummies(df_lstm.Day, prefix='Day')\n",
    "#df_lstm = df_lstm.join(y, how=\"left\")\n",
    "#df_lstm = df_lstm.drop(columns=[\"Day\"])\n",
    "df_lstm = df_lstm.drop(columns=[\"Global_reactive_power\"])\n",
    "df_lstm2 = df_lstm.resample('d').mean()\n",
    "df_lstm2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078e0b6-030a-4797-9fcf-3464366eb597",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = MinMaxScaler(feature_range=(-1,1))\n",
    "df_lstm2[df_lstm2.columns] = scaler.fit_transform(df_lstm2[df_lstm2.columns])\n",
    "df_lstm2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c6690-dac7-4e55-9645-eb1044d02453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm2 = data_to_supervised(df_lstm2)\n",
    "df_lstm2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466ba6c4-924c-4af4-8c89-9f4459cca6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df_lstm2.values\n",
    "\n",
    "trainsize = 0.8\n",
    "n_rows = round(len(values)*trainsize)\n",
    "print(f\"Taille du trainset : {n_rows}\")\n",
    "\n",
    "train = values[:n_rows, :]\n",
    "test = values[n_rows:, :]\n",
    "\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D format as expected by LSTMs [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42021be-0863-45c8-bf36-303a460e5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(7, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184fb6ce-668c-44df-858f-d3957c34b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(train_X, train_y, epochs=75, batch_size=1, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf8863-9085-4b2d-bf7a-3855596e43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()\n",
    "size = df_lstm.shape[1]-1\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], size))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1-size:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1-size:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de96648-db19-4bed-8332-a4712ee2dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ee0e1e-12e5-44c4-af4b-fdf548e65ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "r2 = sklearn.metrics.r2_score(inv_y, inv_yhat)\n",
    "print(r2)\n",
    "r_adjusted = 1 - ( 1-r2 ) * ( len(test_y) - 1 ) / ( len(test_y) - test_X.shape[1] - 1 )\n",
    "print(r_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a678a-b8e1-47f2-aa03-23adbf86d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=[x for x in range(100)]\n",
    "plt.figure(figsize=(40,10))\n",
    "plt.plot(aa, inv_y[:100], marker='.', label=\"actual\")\n",
    "plt.plot(aa, inv_yhat[:100], 'r', label=\"prediction\")\n",
    "plt.ylabel(df.columns[1], size=15)\n",
    "plt.xlabel('Time step for first 500 days', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede436f1-eae1-4601-b3fd-7816d7158dcf",
   "metadata": {},
   "source": [
    "# LSTM by minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff969e87-2674-4368-bf4c-65cd44a50ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm = df.set_index('DateTime')\n",
    "# df_lstm = df_lstm.resample('h').mean()\n",
    "df_lstm['Date'] = pd.to_datetime(df_lstm.index.date)\n",
    "temperatures = pd.read_csv(\"pre_processing/temperatures.csv\", parse_dates=['Date'], index_col='Date')\n",
    "temperatures['avg_t'] = (temperatures['max_t'] - temperatures['min_t'])/2\n",
    "df_lstm = df_lstm.join(temperatures, how=\"left\", on='Date')\n",
    "df_lstm = df_lstm.drop(columns=['Date','max_t','min_t'])\n",
    "#df_lstm[\"Day\"] = df_lstm.index.dayofweek+1\n",
    "#y = pd.get_dummies(df_lstm.Day, prefix='Day')\n",
    "#df_lstm = df_lstm.join(y, how=\"left\")\n",
    "#df_lstm = df_lstm.drop(columns=[\"Day\"])\n",
    "df_lstm = df_lstm.drop(columns=[\"Global_reactive_power\"])\n",
    "# df_lstm2 = df_lstm.resample('d').mean()\n",
    "# df_lstm2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87a9cb-13a7-439f-b815-87b6e9813c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "df_lstm[df_lstm.columns] = scaler.fit_transform(df_lstm[df_lstm.columns])\n",
    "df_lstm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48d6145-52d7-4762-842a-e0499b4cd8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm = data_to_supervised(df_lstm)\n",
    "df_lstm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb493bbe-9229-4d29-ae9c-7c3aff785db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df_lstm.values\n",
    "\n",
    "trainsize = 0.80\n",
    "n_rows = round(len(values)*trainsize)\n",
    "print(f\"Taille du trainset : {n_rows}\")\n",
    "\n",
    "train = values[:n_rows, :]\n",
    "test = values[n_rows:, :]\n",
    "\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to be 3D format as expected by LSTMs [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286e3797-d05a-4d60-8c81-378f1707a4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(3*60, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9bbc7-03fc-465a-8df5-fb102e7d5a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_y, epochs=5, batch_size=100, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd39967-f692-45d3-ab17-265da4f195b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e41f42a-5d3c-4c9b-aa72-a5f4a7b7500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = df_lstm.shape[1]-1\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], size))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, 1-size:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1-size:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba37ea3-6878-4730-960d-d380df1256f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a338eff-82af-4c5d-bb00-e0bc2dbeb536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "r2 = sklearn.metrics.r2_score(inv_y, inv_yhat)\n",
    "print(r2)\n",
    "r_adjusted = 1 - ( 1-r2 ) * ( len(test_y) - 1 ) / ( len(test_y) - test_X.shape[1] - 1 )\n",
    "print(r_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f081c-daf8-4ca6-9fc4-29b68d6e0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_step = 100\n",
    "aa=[x for x in range(nbr_step)]\n",
    "plt.figure(figsize=(40,10))\n",
    "plt.plot(aa, inv_y[:nbr_step], marker='.', label=\"actual\")\n",
    "plt.plot(aa, inv_yhat[:nbr_step], 'r', label=\"prediction\")\n",
    "plt.ylabel(df.columns[1], size=15)\n",
    "plt.xlabel(f'Time step for first {nbr_step} time units', size=15)\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "data_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
